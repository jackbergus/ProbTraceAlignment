\section{Related Works}
%%%
%%%
\paragraph*{Stochastic Conformance Checking.} Earlier works on probabilistic trace alignments \cite{AlizadehLZ14a} extended alignment cost functions by considering probabilities that an activity never eventually occurs when activities on both traces do not correspond. Otherwise, such functions always return zero once activity match. This approach favors traces providing optimal alignment: this approach is not ideal for ranking traces, as the resulting ranking provides no trade-off between trace probability and alignment cost. Furthermore, the computation of the aforementioned probability requires the combined provision of a log file and a non-stochastic Petri Net, our proposed solution estimates trace probability by directly assessing Stochastic Petri Nets. After considering that the formers could be always used to estimate the latter \cite{spdwe}, we can deduce that our proposed solution proves to be more general that this first attempt to probabilistic trace alignments. 

More recent works on stochastic model checking \cite{DBLP:conf/icpm/PolyvyanyyK19,DBLP:journals/tosem/PolyvyanyySWCM20} assess the degree of conformance of the whole stochastic model against one single log trace, thus considering the probability distribution of the whole model. On the other hand, we are interested in determining which is the best model trace providing the trade-off between trace probability and alignment cost with the log trace to be aligned, thus limiting the model probability distribution to the part generating one sole given trace at a time. Therefore, such approaches allow to rank models according to the conformance of a give log trace while, on the other hand, our proposed solutions ranks model traces according to one fixed stochastic model. 

 
%%%
%%%
\paragraph*{Graph Kernels.} Graph kernels express similarity measures \cite{Samatova} involved in both classification \cite{TsudaS10} and clustering algorithms. One of the first approaches required a preliminary embedding definition of topological description vectors extracted from the most frequent subgraphs within a graph database \cite{Sidere}. As a drawback, it required the computation of a subgraph isomorphism problem, which is NP-complete. In fact, the definition of a graph kernel function fully recognizing the structure the graph always boils down to solving such NP-Complete problem \cite{GartnerFW03}, as exact embeddings generable in polynomial can be inferred just for loop-free Direct Acyclic Graphs \cite{BergamiBM20}. Consequently, most recent literature focused on extracting relevant features of such graphs, that are then used to define a graph similarity function. The most common approach adopted in the kernel to extract such features is called \textit{propositionalization}: we might extract all the possible features (e.g., subsequences), and then define a kernel function based on the occurrence and similarity of these features \cite{Gartner03}. For node-labelled graphs, the features come from the node labels and the possible strings that might be generated while traversing the graph (see \cite{Gartner03} and \S\ref{subsec:katk}). 