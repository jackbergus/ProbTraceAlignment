\section{Related Works}
%%%
%%%
\paragraph*{Stochastic Conformance Checking} earlier works on probabilistic trace alignments \cite{AlizadehLZ14a} extended alignment cost functions by considering probabilities of never occurring activities when activities on both traces do not match. Such functions always return a zero cost alignment cost on identical matching traces, independently from the probability associated to the model trace. This approach favors traces providing optimal alignment cost: the resulting ranking cannot be used to provide a trade-off between trace probability and alignment cost. As the model has non-stochastic Petri Net as a reference model, the computation of the aforementioned probability for activities' mismatch requires a log file for providing such an estimation as the more recent work \cite{spdwe}, while our proposed solution might as well estimate trace probability by directly loading Stochastic Petri Nets. We  deduce that our proposed solution proves to be more general that this first attempt to probabilistic trace alignments. 

More recent works on stochastic model checking  assess the degree of conformance of the whole stochastic model against either one single log trace \cite{DBLP:conf/icpm/PolyvyanyyK19,DBLP:journals/tosem/PolyvyanyySWCM20} or an entire log \cite{LeemansSA19}, and consider Stochastic Petri Nets. %On the other hand, we are interested in determining which is the best model trace providing the trade-off between trace probability and alignment cost with the log trace to be aligned, thus limiting the model probability distribution to the part generating one sole given trace at a time. Therefore, such 
With respect to the formers, we might rank models according to the conformance of a give log trace while, on the other hand, our proposed solutions ranks model traces according to one fixed stochastic model. For this reason, we can also exploit our solution to rank stochastic models, while the former is not possible, as process distributions are considered as a whole.  Furthermore, approaches considering entire logs as a whole cannot be possibly exploited for aligning one stochastic model to a single log trace \cite{LeemansSA19}, as for our assumptions the remaining log traces remain unknown, and therefore it is impossible to ``earth-move'' probability distribution from a stochastic model towards a set of unknown traces except one. Furthermore, our approximated ranking approach reduces the alignment problem to the computation of the Euclidean Distance independently from the log trace that we want to align, thus avoiding the cost of repeatedly extracting the model traces and providing an ad-hoc vectorial representation. Nevertheless, such re-computation is always possible for our optimal ranking representation.

 
%%%
%%%
\paragraph*{Graph Kernels} hraph kernels express similarity measures \cite{Samatova} involved in both classification \cite{TsudaS10} and clustering algorithms. One of the first approaches required a preliminary embedding definition of topological description vectors extracted from the most frequent subgraphs within a graph database \cite{Sidere}. As a drawback, it required the computation of a subgraph isomorphism problem, which is NP-complete. In fact, the definition of a graph kernel function fully recognizing the structure the graph always boils down to solving such NP-Complete problem \cite{GartnerFW03}, as exact embeddings generable in polynomial can be inferred just for loop-free Direct Acyclic Graphs \cite{BergamiBM20}. Consequently, most recent literature focused on extracting relevant features of such graphs, that are then used to define a graph similarity function. The most common approach adopted in the kernel to extract such features is called \textit{propositionalization}: we might extract all the possible features (e.g., subsequences), and then define a kernel function based on the occurrence and similarity of these features \cite{Gartner03}. For node-labelled graphs, the features come from the node labels and the possible strings that might be generated while traversing the graph (see \cite{Gartner03} and \S\ref{subsec:katk}). 