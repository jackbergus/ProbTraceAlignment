\section{Related Work}
%%%
%%%
\paragraph*{Stochastic Conformance Checking} earlier work on probabilistic conformance checking, presented in \cite{AlizadehLZ14a}, is based on non-stochastic Petri nets and extends the alignment cost functions by considering the probabilities of activities to be added/deleted when a log trace and a model trace do not match. Such functions always return a zero alignment cost on matching traces, independently of the probability associated to the model trace so that the resulting ranking cannot be used to provide a trade-off between trace probability and alignment cost.
%As the model has non-stochastic Petri Net as a reference model, the computation of the aforementioned probability for activities' mismatch requires a log file for providing such an estimation as the more recent work \cite{spdwe}, while our proposed solution might as well estimate trace probability by directly loading Stochastic Petri Nets.

More recent works on probabilistic conformance checking assess the degree of conformance of a Stochastic Petri net against either one single log trace \cite{DBLP:conf/icpm/PolyvyanyyK19,DBLP:journals/tosem/PolyvyanyySWCM20} or against an entire log \cite{LeemansSA19}. %On the other hand, we are interested in determining which is the best model trace providing the trade-off between trace probability and alignment cost with the log trace to be aligned, thus limiting the model probability distribution to the part generating one sole given trace at a time. Therefore, such
The former approaches might be used to rank different stochastic models according to their degree of conformance with respect to a fixed log trace, while our proposed solution ranks a subset of the model traces of the same stochastic model with respect to a given log trace. Albeit the input of such approaches is the same as ours, the problem that we intend to solve is different. Nevertheless, we might exploit our solution to rank stochastic models via the best trace alignment provided by each single model. Furthermore, approaches evaluating the conformance of a stochastic model against a log as a whole cannot be possibly exploited for aligning a stochastic model and a single log trace, since, apart from the log trace to be aligned, the remaining log traces are not necessarily known, and therefore it is impossible to ``earth-move'' the probability distribution of a stochastic model towards a set of unknown traces.
%Our approximated ranking approach reduces the alignment problem to the computation of the Euclidean distance independently of the log trace that we want to align, thus avoiding the cost of repeatedly extracting the model traces and providing an ad-hoc vectorial representation. Such re-computation is still doable in our optimal ranking representation.


%%%
%%%
\paragraph*{Graph Kernels} graph kernels express similarity measures \cite{Samatova} involved in both classification and clustering algorithms \cite{TsudaS10}. One of the first approaches required a preliminary embedding definition of topological description vectors extracted from the most frequent subgraphs within a graph database \cite{Sidere}. As a drawback, it required the computation of a subgraph isomorphism problem, which is NP-complete \cite{GartnerFW03}. 
%In fact, the definition of a graph kernel function fully recognizing the structure the graph always boils down to solving such NP-Complete problem \cite{GartnerFW03}, as exact embeddings generable in polynomial can be inferred just for loop-free Direct Acyclic Graphs \cite{BergamiBM20}. 
Consequently, more recent literature focuses on extracting relevant features of such graphs, which are then used to define a graph similarity function. The most common approach adopted to extract such features is called \textit{propositionalization}: we might extract all the possible features (e.g., subsequences), and then define a kernel function based on the occurrence and similarity of these features \cite{Gartner03}. For node-labeled graphs, the features come from the node labels and the possible strings that might be generated while traversing the graph (see \cite{Gartner03} and \S\ref{subsec:katk}). 